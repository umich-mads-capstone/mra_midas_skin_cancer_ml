{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67878c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0becc2",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c28f3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mra_midas_skin_cancer_ml.utils.process_metadata import (\n",
    "    create_lesion_key,\n",
    "    dedupe_metadata,\n",
    "    drop_na_target_img,\n",
    "    import_metadata,\n",
    "    process_target,\n",
    "    get_data_dir,\n",
    "    export_metadata,\n",
    ")\n",
    "\n",
    "from mra_midas_skin_cancer_ml.utils.validate_data import (\n",
    "    check_split_ratios,\n",
    "    count_files_in_image_folders,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a203f",
   "metadata": {},
   "source": [
    "# Split Data Based On Image Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83bcae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing files: 12\n",
      "No file found: s-prd-502892079.jpg\n",
      "No file found: s-prd-539536718.jpg\n",
      "No file found: s-prd-539536620.jpg\n",
      "No file found: s-prd-709811242.jpeg\n",
      "No file found: s-prd-656881902.jpg\n",
      "No file found: s-prd-656882615.jpg\n",
      "No file found: s-prd-656882465.jpg\n",
      "No file found: s-prd-675941199.jpeg\n",
      "No file found: s-prd-692721767.jpeg\n",
      "No file found: s-prd-722591153.jpeg\n",
      "No file found: s-prd-722591152.jpeg\n",
      "No file found: s-prd-798621909.jpg\n",
      "\n",
      "Is unique: True\n",
      "Unique count: 1035 \n",
      "\n",
      "1ft is unique: True\n",
      "1ft unique lesions: 1021 \n",
      "\n",
      "6in is unique: True\n",
      "6in unique lesions: 1028 \n",
      "\n",
      "dscope is unique: True\n",
      "dscope unique lesions: 1028 \n",
      "\n",
      "Total unique lesions: 1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_metadata_for_img():\n",
    "    \"\"\"Process metadata for image splitting.\"\"\"\n",
    "\n",
    "    meta_df = import_metadata()\n",
    "    meta_df = process_target(meta_df)\n",
    "    meta_df = drop_na_target_img(meta_df)\n",
    "    dedupe_df = dedupe_metadata(meta_df)\n",
    "\n",
    "    meta_df = create_lesion_key(meta_df)\n",
    "    merge_df = pd.merge(\n",
    "        meta_df,\n",
    "        dedupe_df[[\"lesion_key\", \"midas_path_binary\"]],\n",
    "        on=[\"lesion_key\", \"midas_path_binary\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    return merge_df\n",
    "\n",
    "\n",
    "def split_metadata_dist():\n",
    "    \"\"\"Split metadata based on image distance (\"1ft\", \"6in\", \"dscope\").\"\"\"\n",
    "\n",
    "    meta_df = process_metadata_for_img()\n",
    "\n",
    "    dist_dict = {}\n",
    "\n",
    "    cols = [\n",
    "        \"lesion_key\",\n",
    "        \"midas_record_id\",\n",
    "        \"midas_file_name\",\n",
    "        \"matched_file\",\n",
    "        \"midas_path_binary\",\n",
    "    ]\n",
    "\n",
    "    total_unique_lesions = set()\n",
    "\n",
    "    for dist in [\"1ft\", \"6in\", \"dscope\"]:\n",
    "        subset_df = meta_df[meta_df[\"midas_distance\"] == dist]\n",
    "        subset_df = subset_df[cols]\n",
    "\n",
    "        # Drop multiple images per lesion\n",
    "        subset_df = subset_df.drop_duplicates(\n",
    "            subset=[\"lesion_key\", \"midas_path_binary\"]\n",
    "        )\n",
    "\n",
    "        print(f\"{dist} is unique: {subset_df['lesion_key'].is_unique}\")\n",
    "        unique_count = subset_df[\"lesion_key\"].nunique()\n",
    "        print(f\"{dist} unique lesions: {unique_count} \\n\")\n",
    "\n",
    "        total_unique_lesions.update(subset_df[\"lesion_key\"].tolist())\n",
    "\n",
    "        dist_dict[dist] = subset_df\n",
    "\n",
    "    print(f\"Total unique lesions: {len(total_unique_lesions)}\\n\")\n",
    "\n",
    "    return dist_dict\n",
    "\n",
    "\n",
    "dist_dict = split_metadata_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63b6bc",
   "metadata": {},
   "source": [
    "# Split Each Image Set Into Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c9158e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Master lesion_key split distribution:\n",
      "split\n",
      "train    828\n",
      "test     104\n",
      "val      103\n",
      "Name: count, dtype: int64\n",
      "total 1035\n",
      "split\n",
      "train    0.800000\n",
      "test     0.100483\n",
      "val      0.099517\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "1ft\n",
      "Split raw counts\n",
      "split\n",
      "train    815\n",
      "test     104\n",
      "val      102\n",
      "Name: count, dtype: int64\n",
      "total 1021\n",
      "\n",
      "Split proportions:\n",
      "split\n",
      "train    0.798237\n",
      "test     0.101861\n",
      "val      0.099902\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target proportions by split:\n",
      "split  midas_path_binary\n",
      "test   benign               0.500000\n",
      "       malignant            0.500000\n",
      "train  benign               0.512883\n",
      "       malignant            0.487117\n",
      "val    malignant            0.529412\n",
      "       benign               0.470588\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "6in\n",
      "Split raw counts\n",
      "split\n",
      "train    821\n",
      "test     104\n",
      "val      103\n",
      "Name: count, dtype: int64\n",
      "total 1028\n",
      "\n",
      "Split proportions:\n",
      "split\n",
      "train    0.798638\n",
      "test     0.101167\n",
      "val      0.100195\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target proportions by split:\n",
      "split  midas_path_binary\n",
      "test   benign               0.500000\n",
      "       malignant            0.500000\n",
      "train  benign               0.511571\n",
      "       malignant            0.488429\n",
      "val    malignant            0.524272\n",
      "       benign               0.475728\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "dscope\n",
      "Split raw counts\n",
      "split\n",
      "train    822\n",
      "test     103\n",
      "val      103\n",
      "Name: count, dtype: int64\n",
      "total 1028\n",
      "\n",
      "Split proportions:\n",
      "split\n",
      "train    0.799611\n",
      "test     0.100195\n",
      "val      0.100195\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target proportions by split:\n",
      "split  midas_path_binary\n",
      "test   malignant            0.504854\n",
      "       benign               0.495146\n",
      "train  benign               0.509732\n",
      "       malignant            0.490268\n",
      "val    malignant            0.524272\n",
      "       benign               0.475728\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def split_train_test_by_lesion(dist_dict, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split dataframes for each image distance into train/val/test sets by lesion_key.\n",
    "    \"\"\"\n",
    "    # Get all unique lesion_keys across distances\n",
    "    all_keys = pd.concat(\n",
    "        [df[\"lesion_key\"] for df in dist_dict.values()]\n",
    "    ).unique()\n",
    "\n",
    "    # Split lesion keys into train, val and test\n",
    "    train_keys, val_test_keys = train_test_split(\n",
    "        all_keys, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    val_keys, test_keys = train_test_split(\n",
    "        val_test_keys, test_size=0.5, random_state=random_state\n",
    "    )\n",
    "\n",
    "    master_split_df = pd.DataFrame({\"lesion_key\": all_keys})\n",
    "\n",
    "    def assign_master_split(key):\n",
    "        if key in train_keys:\n",
    "            return \"train\"\n",
    "        elif key in val_keys:\n",
    "            return \"val\"\n",
    "        else:\n",
    "            return \"test\"\n",
    "\n",
    "    master_split_df[\"split\"] = master_split_df[\"lesion_key\"].apply(\n",
    "        assign_master_split\n",
    "    )\n",
    "\n",
    "    # Assign splits for each distance based on lesion key\n",
    "    result_dict = {}\n",
    "    data_dir = get_data_dir()\n",
    "\n",
    "    for dist, subset_df in dist_dict.items():\n",
    "        df = subset_df.copy()\n",
    "        df[\"split\"] = df[\"lesion_key\"].apply(assign_master_split)\n",
    "\n",
    "        result_dict[dist] = df\n",
    "\n",
    "        export_metadata(\n",
    "            df, data_dir / \"output\" / f\"{dist}_split_image_data.xlsx\"\n",
    "        )\n",
    "\n",
    "    export_metadata(\n",
    "        master_split_df,\n",
    "        data_dir / \"output\" / \"master_lesion_split_lookup.xlsx\",\n",
    "    )\n",
    "\n",
    "    print(\"\\nMaster lesion_key split distribution:\")\n",
    "    print(master_split_df[\"split\"].value_counts())\n",
    "    print(f\"total {len(master_split_df)}\")\n",
    "    print(master_split_df[\"split\"].value_counts(normalize=True))\n",
    "\n",
    "    check_split_ratios(result_dict)\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "result_dict = split_train_test_by_lesion(dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08145f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 1ft ===\n",
      "train / benign   : 418\n",
      "train / malignant: 397\n",
      "val   / benign   : 48\n",
      "val   / malignant: 54\n",
      "test  / benign   : 52\n",
      "test  / malignant: 52\n",
      "\n",
      "=== 6in ===\n",
      "train / benign   : 420\n",
      "train / malignant: 401\n",
      "val   / benign   : 49\n",
      "val   / malignant: 54\n",
      "test  / benign   : 52\n",
      "test  / malignant: 52\n",
      "\n",
      "=== dscope ===\n",
      "train / benign   : 419\n",
      "train / malignant: 403\n",
      "val   / benign   : 49\n",
      "val   / malignant: 54\n",
      "test  / benign   : 51\n",
      "test  / malignant: 52\n"
     ]
    }
   ],
   "source": [
    "def create_image_folders(result_dict, raw_images_dir, output_root_dir):\n",
    "    \"\"\"\n",
    "    Creates folders and copies images into train/val/test.\n",
    "    Match case-insensitive filenames (.jpg/.jpeg/_cropped.jpg/_cropped.jpeg)\n",
    "    \"\"\"\n",
    "\n",
    "    raw_images_dir = Path(raw_images_dir)\n",
    "    output_root_dir = Path(output_root_dir)\n",
    "\n",
    "    all_files_map = {\n",
    "        p.name.lower(): p for p in raw_images_dir.iterdir() if p.is_file()\n",
    "    }\n",
    "\n",
    "    for dist, df in result_dict.items():\n",
    "        dist_dir = output_root_dir / dist\n",
    "\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            for label in [\"benign\", \"malignant\"]:\n",
    "                (dist_dir / split / label).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for row in df.itertuples(index=False):\n",
    "            excel_name = row.midas_file_name.lower()\n",
    "            label = row.midas_path_binary\n",
    "            split = row.split\n",
    "\n",
    "            stem = Path(excel_name).stem  # base without extension\n",
    "\n",
    "            candidates = [\n",
    "                f\"{stem}.jpg\",\n",
    "                f\"{stem}.jpeg\",\n",
    "                f\"{stem}_cropped.jpg\",\n",
    "                f\"{stem}_cropped.jpeg\",\n",
    "            ]\n",
    "\n",
    "            matched_file = None\n",
    "            for candidate in candidates:\n",
    "                if candidate in all_files_map:\n",
    "                    matched_file = all_files_map[candidate]\n",
    "                    break\n",
    "\n",
    "            if matched_file is None:\n",
    "                print(f\"No file found for: {row.midas_file_name}\")\n",
    "                continue\n",
    "\n",
    "            dst_path = dist_dir / split / label / matched_file.name\n",
    "            shutil.copy2(matched_file, dst_path)\n",
    "\n",
    "    count_files_in_image_folders(output_root_dir)\n",
    "\n",
    "\n",
    "create_image_folders(\n",
    "    result_dict,\n",
    "    get_data_dir() / \"input\" / \"raw_images\",\n",
    "    get_data_dir() / \"output\" / \"split_images\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
